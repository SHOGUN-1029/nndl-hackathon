{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas faiss-cpu sentence-transformers transformers --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# Load your IPC dataset\n",
        "df = pd.read_csv(\"/content/ipc_sections.csv\")  # Automatically picks the uploaded file\n",
        "\n",
        "# Extract Columns\n",
        "descriptions = df['Description'].tolist()\n",
        "sections = df['Section'].tolist()\n",
        "offenses = df['Offense'].tolist()\n",
        "punishments = df['Punishment'].tolist()\n",
        "\n",
        "# Load SBERT Model for Embeddings\n",
        "print(\"Loading sentence transformer model...\")\n",
        "embedder = SentenceTransformer(\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
        "\n",
        "# Create Embeddings\n",
        "print(\"Creating embeddings...\")\n",
        "embeddings = embedder.encode(descriptions, convert_to_numpy=True)\n",
        "\n",
        "# Build FAISS Index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "# Load Free LLM (No API Key)\n",
        "print(\"Loading legal text generation model...\")\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "llm_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "generator = pipeline(\"text2text-generation\", model=llm_model, tokenizer=tokenizer)\n",
        "\n",
        "# Function to search IPC Sections\n",
        "def find_ipc_section(case_description, k=3):\n",
        "    query_embedding = embedder.encode([case_description], convert_to_numpy=True)\n",
        "    D, I = index.search(query_embedding, k)\n",
        "    results = []\n",
        "    for i in range(k):\n",
        "        sec_num = sections[I[0][i]]\n",
        "        sec_desc = descriptions[I[0][i]]\n",
        "        offense = offenses[I[0][i]]\n",
        "        punishment = punishments[I[0][i]]\n",
        "        results.append((sec_num, offense, punishment, sec_desc, D[0][i]))\n",
        "    return results\n",
        "\n",
        "# Function to Generate Legal Document with formatted IPC sections\n",
        "def generate_legal_doc(case_input, retrieved_sections):\n",
        "    # Header\n",
        "    legal_doc = \"LEGAL CASE ANALYSIS REPORT\\n\\n\"\n",
        "    legal_doc += \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "    # Case Summary\n",
        "    legal_doc += \"CASE DESCRIPTION:\\n\"\n",
        "    legal_doc += f\"{case_input}\\n\\n\"\n",
        "    legal_doc += \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "    # Applicable IPC Sections\n",
        "    legal_doc += \"APPLICABLE IPC SECTIONS:\\n\\n\"\n",
        "    for i, (sec, off, pun, desc, _) in enumerate(retrieved_sections, 1):\n",
        "        legal_doc += f\"{i}. Section {sec}\\n\"\n",
        "        legal_doc += f\"   - Offense: {off}\\n\"\n",
        "        legal_doc += f\"   - Punishment: {pun}\\n\"\n",
        "        legal_doc += f\"   - Description: {desc}\\n\\n\"\n",
        "\n",
        "    legal_doc += \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "    # Legal Analysis prompt\n",
        "    prompt = f\"\"\"\n",
        "    Based on the case description: \"{case_input}\"\n",
        "\n",
        "    And the following applicable IPC sections:\n",
        "    {[sec for sec, _, _, _, _ in retrieved_sections]}\n",
        "\n",
        "    Provide a detailed legal analysis that:\n",
        "    1. Explains how each IPC section applies to the case facts\n",
        "    2. Discusses potential defenses\n",
        "    3. Analyzes the severity of the offenses\n",
        "    4. Estimates likely legal outcomes\n",
        "\n",
        "    Write in professional legal language suitable for court documentation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate analysis\n",
        "    analysis = generator(prompt, max_length=1024, do_sample=True, temperature=0.7)[0]['generated_text']\n",
        "\n",
        "    legal_doc += \"LEGAL ANALYSIS:\\n\\n\"\n",
        "    legal_doc += analysis + \"\\n\\n\"\n",
        "    legal_doc += \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "    # Conclusion\n",
        "    legal_doc += \"CONCLUSION:\\n\"\n",
        "    legal_doc += \"Based on the above analysis, this case appears to involve violations of \"\n",
        "    legal_doc += \", \".join([f\"Section {sec}\" for sec, _, _, _, _ in retrieved_sections[:-1]])\n",
        "    if len(retrieved_sections) > 1:\n",
        "        legal_doc += f\", and Section {retrieved_sections[-1][0]}\"\n",
        "    else:\n",
        "        legal_doc += f\"Section {retrieved_sections[0][0]}\"\n",
        "    legal_doc += \" of the Indian Penal Code.\\n\\n\"\n",
        "\n",
        "    return legal_doc\n",
        "\n",
        "# Main execution\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"IPC SECTION FINDER AND LEGAL DOCUMENT GENERATOR\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "case_input = input(\"Enter the case details: \")\n",
        "\n",
        "print(\"\\nSearching for relevant IPC sections...\")\n",
        "retrieved = find_ipc_section(case_input, k=3)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RETRIEVED IPC SECTIONS:\")\n",
        "print(\"=\"*50)\n",
        "for i, (sec, off, pun, desc, dist) in enumerate(retrieved, 1):\n",
        "    print(f\"\\n{i}. Section {sec}\")\n",
        "    print(f\"   Offense: {off}\")\n",
        "    print(f\"   Punishment: {pun}\")\n",
        "    print(f\"   Description: {desc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"GENERATING LEGAL DOCUMENT...\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "legal_document = generate_legal_doc(case_input, retrieved)\n",
        "print(legal_document)\n",
        "\n",
        "# Option to save the document\n",
        "save_option = input(\"\\nWould you like to save this document? (yes/no): \")\n",
        "if save_option.lower() == 'yes':\n",
        "    filename = input(\"Enter filename (without extension): \") + \".txt\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(legal_document)\n",
        "    print(f\"Document saved as {filename}\")"
      ],
      "metadata": {
        "id": "2bAJ1QixrVHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}