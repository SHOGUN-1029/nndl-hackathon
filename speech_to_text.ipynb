{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHp_1RRnrUV3"
      },
      "outputs": [],
      "source": [
        "pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "def speech_to_text(audio_file, translate=False):\n",
        "    model = whisper.load_model(\"small\")  # Load the Whisper model\n",
        "\n",
        "    # Choose between transcription and translation\n",
        "    result = model.transcribe(audio_file, task=\"translate\" if translate else \"transcribe\")\n",
        "\n",
        "    return result[\"text\"]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_path = \"/content/judgement_0.mp3\"  # Replace with your file path\n",
        "\n",
        "    # Transcribe in the original language\n",
        "    text_output = speech_to_text(audio_path)\n",
        "    print(\"Transcribed Text:\", text_output)\n",
        "\n",
        "    # Translate to English if the audio is in an Indian language\n",
        "    translated_output = speech_to_text(audio_path, translate=True)\n",
        "    print(\"Translated Text:\", translated_output)\n"
      ],
      "metadata": {
        "id": "2bAJ1QixrVHJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}